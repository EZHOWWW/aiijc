{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d60d11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (2.32.4)\n",
      "Requirement already satisfied: tqdm in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: trimesh in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (4.7.1)\n",
      "Requirement already satisfied: thingi10k in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy-stl in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (3.2.0)\n",
      "Requirement already satisfied: numpy in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (2.3.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: datasets>=4.0 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from thingi10k) (4.0.0)\n",
      "Requirement already satisfied: polars>=1.0 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from thingi10k) (1.32.0)\n",
      "Requirement already satisfied: lagrange-open>=6.29.0 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from thingi10k) (6.35.0)\n",
      "Requirement already satisfied: python-utils>=3.4.5 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from numpy-stl) (3.9.1)\n",
      "Requirement already satisfied: filelock in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from datasets>=4.0->thingi10k) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from datasets>=4.0->thingi10k) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from datasets>=4.0->thingi10k) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from datasets>=4.0->thingi10k) (2.3.1)\n",
      "Requirement already satisfied: xxhash in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from datasets>=4.0->thingi10k) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from datasets>=4.0->thingi10k) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0->thingi10k) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from datasets>=4.0->thingi10k) (0.34.3)\n",
      "Requirement already satisfied: packaging in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from datasets>=4.0->thingi10k) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from datasets>=4.0->thingi10k) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0->thingi10k) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0->thingi10k) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0->thingi10k) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0->thingi10k) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0->thingi10k) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0->thingi10k) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0->thingi10k) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0->thingi10k) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets>=4.0->thingi10k) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets>=4.0->thingi10k) (1.1.5)\n",
      "Requirement already satisfied: colorama>=0.4.4 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from lagrange-open>=6.29.0->thingi10k) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from pandas->datasets>=4.0->thingi10k) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from pandas->datasets>=4.0->thingi10k) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from pandas->datasets>=4.0->thingi10k) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/dima/miniconda3/envs/aiijcenv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=4.0->thingi10k) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests tqdm trimesh thingi10k numpy-stl numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cc90ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import shutil\n",
    "import trimesh\n",
    "import thingi10k\n",
    "import numpy as np\n",
    "from stl import mesh\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urlencode\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a284018f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetsManager initialized. All data will be stored in 'my_3d_datasets'\n",
      "\n",
      "[3/3] Processing Custom Dataset from Yandex.Disk...\n",
      "Starting to process link: https://disk.yandex.ru/d/RRXJu9ZtEmSXzQ\n",
      "Direct download link obtained.\n",
      "Downloading file...\n",
      "File 'temp_download.zip' downloaded successfully.\n",
      "Unzipping archive to folder 'my_3d_datasets'...\n",
      "Files successfully unzipped to 'my_3d_datasets'.\n",
      "Temporary file 'temp_download.zip' has been removed.\n",
      "Starting to process link: https://disk.yandex.ru/d/TmbB7BsGzg1dQQ\n",
      "Direct download link obtained.\n",
      "Downloading file...\n",
      "File 'temp_download.zip' downloaded successfully.\n",
      "Unzipping archive to folder 'my_3d_datasets'...\n",
      "Files successfully unzipped to 'my_3d_datasets'.\n",
      "Temporary file 'temp_download.zip' has been removed.\n",
      "Custom dataset preparation complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class DatasetsManager:\n",
    "    \"\"\"\n",
    "    A manager class to download, process, and structure 3D datasets for ML tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir=\"data\"):\n",
    "        \"\"\"\n",
    "        Initializes the manager with a root directory for all data.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.thingi10k_dir = os.path.join(root_dir, \"thingi10k\")\n",
    "        self.modelnet_dir = os.path.join(root_dir, \"ModelNet40\")\n",
    "        self.custom_data_dir = os.path.join(root_dir, \"custom_dataset\")\n",
    "        os.makedirs(self.root_dir, exist_ok=True)\n",
    "        print(f\"DatasetsManager initialized. All data will be stored in '{self.root_dir}'\")\n",
    "\n",
    "    def prepare_all_datasets(self):\n",
    "        \"\"\"Runs the preparation process for all configured datasets.\"\"\"\n",
    "        print(\"\\n--- Starting all dataset preparation processes ---\")\n",
    "        self.prepare_thingi10k()\n",
    "        self.prepare_modelnet40()\n",
    "        self.prepare_custom_dataset()\n",
    "        print(\"\\n--- All dataset preparation processes are complete! ---\")\n",
    "\n",
    "    def prepare_thingi10k(self):\n",
    "        \"\"\"Prepares the Thingi10k dataset: converts .npz to .stl into a 'models' folder.\"\"\"\n",
    "        print(\"\\n[1/3] Processing Thingi10k...\")\n",
    "        models_out_dir = os.path.join(self.thingi10k_dir, \"models\")\n",
    "        os.makedirs(models_out_dir, exist_ok=True)\n",
    "\n",
    "        warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"thingi10k\")\n",
    "        thingi10k.init()\n",
    "\n",
    "        for entry in tqdm(thingi10k.dataset(), desc=\"Converting Thingi10k\"):\n",
    "            file_id = entry[\"file_id\"]\n",
    "            output_filepath = os.path.join(models_out_dir, f\"{file_id}.stl\")\n",
    "            if os.path.exists(output_filepath):\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                with np.load(entry[\"file_path\"]) as data:\n",
    "                    vertices = np.asarray(data[\"vertices\"], dtype=np.float64)\n",
    "                    facets = np.asarray(data[\"facets\"], dtype=np.int32)\n",
    "                \n",
    "                mesh_data = vertices[facets]\n",
    "                stl_mesh = mesh.Mesh(np.zeros(mesh_data.shape[0], dtype=mesh.Mesh.dtype))\n",
    "                stl_mesh.vectors = mesh_data\n",
    "                stl_mesh.save(output_filepath)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping Thingi10k file_id {file_id}. Error: {e}\")\n",
    "        print(\"Thingi10k preparation complete.\")\n",
    "\n",
    "    def prepare_modelnet40(self):\n",
    "        \"\"\"Prepares ModelNet40: downloads, flattens structure, and converts .off to .stl.\"\"\"\n",
    "        print(\"\\n[2/3] Processing ModelNet40...\")\n",
    "        url = \"http://modelnet.cs.princeton.edu/ModelNet40.zip\"\n",
    "        zip_path = os.path.join(self.root_dir, \"ModelNet40.zip\")\n",
    "\n",
    "        if not os.path.exists(self.modelnet_dir):\n",
    "            self._download_file(url, zip_path)\n",
    "            print(f\"Extracting {zip_path}...\")\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(self.root_dir)\n",
    "            os.remove(zip_path)\n",
    "\n",
    "        for category_d in tqdm(os.scandir(self.modelnet_dir), desc=\"Processing ModelNet40 categories\"):\n",
    "            if not category_d.is_dir() or category_d.name.startswith('__'):\n",
    "                continue\n",
    "            \n",
    "            models_out_dir = os.path.join(category_d.path, \"models\")\n",
    "            os.makedirs(models_out_dir, exist_ok=True)\n",
    "\n",
    "            for subfolder in [\"train\", \"test\"]:\n",
    "                subfolder_path = os.path.join(category_d.path, subfolder)\n",
    "                if not os.path.exists(subfolder_path):\n",
    "                    continue\n",
    "                \n",
    "                for off_file in os.scandir(subfolder_path):\n",
    "                    if off_file.name.endswith(\".off\"):\n",
    "                        stl_filename = off_file.name.replace(\".off\", \".stl\")\n",
    "                        stl_filepath = os.path.join(models_out_dir, stl_filename)\n",
    "                        if os.path.exists(stl_filepath):\n",
    "                            continue\n",
    "                        try:\n",
    "                            mesh = trimesh.load_mesh(off_file.path)\n",
    "                            mesh.export(stl_filepath)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Failed to process {off_file.path}: {e}\")\n",
    "                shutil.rmtree(subfolder_path)\n",
    "        print(\"ModelNet40 preparation complete.\")\n",
    "        \n",
    "    def prepare_custom_dataset(self):\n",
    "        \"\"\"Downloads and structures the custom dataset from Yandex.Disk.\"\"\"\n",
    "        print(\"\\n[3/3] Processing Custom Dataset from Yandex.Disk...\")\n",
    "        os.makedirs(self.custom_data_dir, exist_ok=True)\n",
    "        \n",
    "        files_to_download = {\n",
    "            \"train_data\": \"https://disk.yandex.ru/d/RRXJu9ZtEmSXzQ\",\n",
    "            \"test_data\": \"https://disk.yandex.ru/d/TmbB7BsGzg1dQQ\",\n",
    "        }\n",
    "        for key, val in files_to_download.items():\n",
    "            self.download_and_unzip_yandex_disk(val, self.root_dir)\n",
    "\n",
    "        print(\"Custom dataset preparation complete.\")\n",
    "\n",
    "    def _download_file(self, url, filename):\n",
    "        \"\"\"Helper to download a file with a progress bar.\"\"\"\n",
    "        print(f\"Downloading {url}...\")\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            total_size = int(r.headers.get('content-length', 0))\n",
    "            with open(filename, 'wb') as f, tqdm(\n",
    "                total=total_size, unit='iB', unit_scale=True, desc=filename.split('/')[-1]\n",
    "            ) as bar:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    size = f.write(chunk)\n",
    "                    bar.update(size)\n",
    "\n",
    "    def download_and_unzip_yandex_disk(self, public_url, extract_to_folder):\n",
    "        \"\"\"\n",
    "        Downloads and unzips a file from Yandex.Disk using a public link.\n",
    "\n",
    "        :param public_url: Public URL to the file on Yandex.Disk.\n",
    "        :param extract_to_folder: The folder where the archive will be extracted.\n",
    "        \"\"\"\n",
    "        print(f\"Starting to process link: {public_url}\")\n",
    "\n",
    "        # 1. Get the direct download link from the Yandex.Disk API\n",
    "        base_api_url = \"https://cloud-api.yandex.net/v1/disk/public/resources/download?\"\n",
    "        api_url = base_api_url + urlencode(dict(public_key=public_url))\n",
    "\n",
    "        try:\n",
    "            response = requests.get(api_url)\n",
    "            response.raise_for_status()  # Check for HTTP errors\n",
    "            download_url = response.json().get(\"href\")\n",
    "\n",
    "            if not download_url:\n",
    "                print(f\"Error: Could not get a direct download link for {public_url}\")\n",
    "                return\n",
    "\n",
    "            print(\"Direct download link obtained.\")\n",
    "\n",
    "            # 2. Download the file\n",
    "            print(\"Downloading file...\")\n",
    "            download_response = requests.get(download_url)\n",
    "            download_response.raise_for_status()\n",
    "\n",
    "            # Temporary name for the zip file\n",
    "            zip_filename = \"temp_download.zip\"\n",
    "\n",
    "            with open(zip_filename, \"wb\") as f:\n",
    "                f.write(download_response.content)\n",
    "            print(f\"File '{zip_filename}' downloaded successfully.\")\n",
    "\n",
    "            # 3. Unzip the archive\n",
    "            print(f\"Unzipping archive to folder '{extract_to_folder}'...\")\n",
    "            if not os.path.exists(extract_to_folder):\n",
    "                os.makedirs(extract_to_folder)\n",
    "\n",
    "            with zipfile.ZipFile(zip_filename, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(extract_to_folder)\n",
    "            print(f\"Files successfully unzipped to '{extract_to_folder}'.\")\n",
    "\n",
    "            # 4. Remove the downloaded zip archive\n",
    "            os.remove(zip_filename)\n",
    "            print(f\"Temporary file '{zip_filename}' has been removed.\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"A network or API error occurred: {e}\")\n",
    "            print(\"Tip: Make sure your environment can access 'cloud-api.yandex.net'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- How to use the manager ---\n",
    "    # 1. Create an instance of the manager\n",
    "    manager = DatasetsManager(root_dir=\"my_3d_datasets\")\n",
    "\n",
    "    # 2. Run the preparation for all datasets\n",
    "    manager.prepare_all_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a6489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiijcenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
